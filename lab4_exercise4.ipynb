{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4, Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in the following two CSVs:\n",
    "# data/exercise4/lab4_normal_data.csv\n",
    "# data/exercise4/lab4_malicious_data.csv\n",
    "# The first consists completely of normal data, while the second consists completely of malicious data\n",
    "# Note: Both sets of data contain the same features used in Exercise 1; the data has already been preprocessed\n",
    "# (i.e., you can keep all the features and there are no labels in the CSVs)\n",
    "\n",
    "# CODE HERE\n",
    "norm_data = pd.read_csv('data/exercise4/lab4_normal_data.csv')\n",
    "mal_data = pd.read_csv('data/exercise4/lab4_malicious_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 15 datasets, where the ith dataset consists of:\n",
    "# - all normal data\n",
    "# - only the ith malicious datapoint\n",
    "\n",
    "# CODE HERE\n",
    "datasets = []\n",
    "for i in range(mal_data.shape[0]):\n",
    "    datasets.append(pd.concat([norm_data,mal_data.iloc[i:i+1,:]],ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List index of each attack datapoint:\n",
      "[161, 18579, 1562, 1412, 0, 28441, 15273, 25003, 722, 17906, 139, 364, 364, 1130, 172]\n"
     ]
    }
   ],
   "source": [
    "# For each dataset, run isolation forests\n",
    "#\n",
    "# Use the following evaluation metric:\n",
    "# - rank the anomalousness of each datapoint using the isolation forest\n",
    "# - record the list index of each attack datapoint when sorting from most to least unusual\n",
    "#     - e.g., if the attack datapoint is at index 0 in the list, we want to record the value 0\n",
    "#\n",
    "# Note: don't worry about ties in ranking\n",
    "# Hint: What is the difference between isolation forest's 'decision_function' and 'predict' methods? \n",
    "\n",
    "# CODE HERE\n",
    "from sklearn.ensemble import IsolationForest\n",
    "list_idxs = []\n",
    "for i in range(len(datasets)):\n",
    "    model = IsolationForest(behaviour='new', contamination=0.1, random_state=42).fit(datasets[i])\n",
    "    anom_scores = model.decision_function(datasets[i])\n",
    "    anom_list = [x for x in zip(range(len(anom_scores)), anom_scores)]\n",
    "    anom_list.sort(key=lambda anom: anom[1])\n",
    "    list_idxs.append([x[0] for x in anom_list].index(datasets[i].shape[0]-1))\n",
    "print('List index of each attack datapoint:\\n{}'.format(list_idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1) Why is there no separate training and test set?\n",
    "\n",
    "There is no separate training and test set because this is not a problem using a supervised model, such as regression or classification. This problem utilizes an unsupervised model to \"cluster\" datapoints and find anomalies in the datapoints, which does not require a training and test split.\n",
    "\n",
    "2) What is the metric measuring?  What would be a perfect score?  Bonus: What is the expected performance of an outlier detector that assigns a random score to each datapoint?\n",
    "\n",
    "The anomaly score is measuring the degree to which a datapoint is an anomaly, while the index metric measures how anomalous the datapoint is compared to all of the normal data. A perfect score for the index metric would be a 0, indicating that the datapoint is the most anomalous of all the datapoints.\n",
    "\n",
    "3) How well does the isolation forest perform compared to a perfect score? Bonus: How well does the isolation forest perform compared to a random detector?\n",
    "\n",
    "The isolation forest does not perform the best compared to a perfect score, despite getting it once, since there are lots of indexes that are very far off a perfect score.\n",
    "\n",
    "4) What are some issues that would prevent this model from being practically deployed?\n",
    "\n",
    "An issue that would prevent this model from being practically deployed is that a lot of the times it scores the malicious data as not very anomalous compared to the rest of the normal data. As a result, either the malicious data goes undetected or a lot of normal data must be checked if, say, the top 20000 anomalous data points need to be analyzed in order to find the malicious datapoint. Also, if there are lots of malicious datapoints, then they might not seem as \"anomalous\" as they really are and be harder to detect.\n",
    "\n",
    "5) What might happen if we inject five attack datapoints at a time?  What might happen if we inject 100 attack datapoints at a time?\n",
    "\n",
    "With more attack datapoints, their anomaly scores might go down since there are more datapoints similar to the attack ones. With just 5 attack datapoints, there might be very little difference, but with 100 it would be much harder to tell if a datapoint is malicious based on anomaly score.\n",
    "\n",
    "6) What is the effect of the parameters max_features and max_samples?  What other parameters could you adjust to change performance?\n",
    "\n",
    "Max_features specifies the max number of features, or columns, used to train the base tree estimator while max_samples specifies the max number of samples, or rows, used to train the base tree estimator. Some other parameters that could be used to improve performance are contamination, bootstrap, and behavior.\n",
    "\n",
    "Optional: What are some alternative anomaly detection models one could use instead of an isolation forest? Bonus: Try one of these alternatives and compare performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
