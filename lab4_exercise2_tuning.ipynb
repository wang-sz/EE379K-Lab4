{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4, Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "The goal of this exercise is to build a straightforward machine learning pipeline for a problem with more than two classes.  A lot of the data preprocessing has already been done, so the main focus of this exercise is to become familiar with loading data, training a model, doing inference, and analyzing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "For example, here's the first couple rows of the dataset:\n",
    "\n",
    "| Source IP    |  Source Port |  Destination IP   |  Destination Port |  Protocol |  Flow Duration |  Flow Bytes/s |  Flow Packets/s |  Flow IAT Mean |  Flow IAT Std |  Flow IAT Max |  Flow IAT Min | Fwd IAT Mean |  Fwd IAT Std |  Fwd IAT Max |  Fwd IAT Min | Bwd IAT Mean |  Bwd IAT Std |  Bwd IAT Max |  Bwd IAT Min | Active Mean |  Active Std |  Active Max |  Active Min | Idle Mean |  Idle Std |  Idle Max |  Idle Min | label |\n",
    "|--------------|--------------|-------------------|-------------------|-----------|----------------|---------------|-----------------|----------------|---------------|---------------|---------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|--------------|-------------|-------------|-------------|-------------|-----------|-----------|-----------|-----------|-------|\n",
    "| 10\\.0\\.2\\.15 | 57188        | 82\\.161\\.239\\.177 | 110               | 6         | 7248168        | 21126\\.02798  | 29\\.11080428    | 34515\\.08571   | 273869\\.2625  | 3897923       | 5             | 89483\\.55556 | 437167\\.5917 | 3898126      | 29           | 56614\\.03906 | 349855\\.1098 | 3898131      | 7            | 0           | 0           | 0           | 0           | 0         | 0         | 0         | 0         | AUDIO |\n",
    "| 10\\.0\\.2\\.15 | 57188        | 82\\.161\\.239\\.177 | 110               | 6         | 5157723        | 1052\\.790156  | 3\\.683796125    | 286540\\.1667   | 878838\\.5256  | 3743359       | 135           | 644715\\.375  | 1272066\\.058 | 3743562      | 509          | 568901\\.6667 | 1209110\\.287 | 3743573      | 451          | 0           | 0           | 0           | 0           | 0         | 0         | 0         | 0         | AUDIO |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV data as a Pandas dataframe\n",
    "# The data is in 'data/exercise2/TOR_TimeBasedFeatures-10s-Layer2.csv'\n",
    "\n",
    "# CODE HERE\n",
    "csv_data = pd.read_csv('data/exercise2/TOR_TimeBasedFeatures-10s-Layer2.csv')\n",
    "\n",
    "# Create data and labels that can be used by sklearn's 'train_test_split'\n",
    "# Create the labels\n",
    "\n",
    "# CODE HERE\n",
    "labels = csv_data['label']\n",
    "\n",
    "# Create the data\n",
    "# -Keep just the numeric features (i.e., those features between 'Flow Duration' and 'Idle Min')\n",
    "# -Make sure not to keep the labels\n",
    "\n",
    "# CODE HERE\n",
    "data = csv_data.iloc[:,5:28]\n",
    "\n",
    "# You should now have data and labels that can be used by sklearn's 'train_test_split'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a single train/test split for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick 50% of the data for the training set, and keep the remaining 50% for the test set\n",
    "# Use sklearn's 'train_test_split'\n",
    "# CODE HERE\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,labels,test_size=0.5,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest classifier using default hyperparameters\n",
    "# Hint: Not counting any import statements, this can be done in a single line of code\n",
    "# CODE HERE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=100,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=123\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the classifier on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8329189457981104\n",
      "Confusion Matrix:\n",
      "[[ 263   87    3    0    3    3    5    1]\n",
      " [  42  667   16    2    3    1   50    3]\n",
      " [   2  105   50    1    0    1    6    4]\n",
      " [   5   26    3  396    5    0   13    2]\n",
      " [   5   57    3    9   50    2    9    1]\n",
      " [   3    7    1    0    0  532    6    1]\n",
      " [  12   87    3   18   13    7  275    1]\n",
      " [   6   22    1    2    0    0    4 1117]]\n",
      "Confusion Matrix with Labels:\n",
      "                 p:AUDIO  p:BROWSING  p:CHAT  p:FILE-TRANSFER  p:MAIL  p:P2P  \\\n",
      "t:AUDIO              263          87       3                0       3      3   \n",
      "t:BROWSING            42         667      16                2       3      1   \n",
      "t:CHAT                 2         105      50                1       0      1   \n",
      "t:FILE-TRANSFER        5          26       3              396       5      0   \n",
      "t:MAIL                 5          57       3                9      50      2   \n",
      "t:P2P                  3           7       1                0       0    532   \n",
      "t:VIDEO               12          87       3               18      13      7   \n",
      "t:VOIP                 6          22       1                2       0      0   \n",
      "\n",
      "                 p:VIDEO  p:VOIP  \n",
      "t:AUDIO                5       1  \n",
      "t:BROWSING            50       3  \n",
      "t:CHAT                 6       4  \n",
      "t:FILE-TRANSFER       13       2  \n",
      "t:MAIL                 9       1  \n",
      "t:P2P                  6       1  \n",
      "t:VIDEO              275       1  \n",
      "t:VOIP                 4    1117  \n"
     ]
    }
   ],
   "source": [
    "# Predict the labels on the test set\n",
    "\n",
    "# CODE HERE\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Use accuracy and a confusion matrix to measure performance\n",
    "# Hint: Use sklearn's built-in metrics\n",
    "\n",
    "# CODE HERE\n",
    "from sklearn import metrics\n",
    "labels_uniq = csv_data['label'].unique()\n",
    "acc = metrics.accuracy_score(y_test, preds)\n",
    "matrix = metrics.confusion_matrix(y_test, preds, labels=labels_uniq)\n",
    "mat_df = pd.DataFrame(\n",
    "    matrix,\n",
    "    index=['t:'+x for x in labels_uniq],\n",
    "    columns=['p:'+x for x in labels_uniq]\n",
    ")\n",
    "print('Accuracy: {}'.format(acc))\n",
    "print('Confusion Matrix:\\n{}'.format(matrix))\n",
    "print('Confusion Matrix with Labels:\\n{}'.format(mat_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature\t\tImportance\n",
      "Flow IAT Min\t0.10533890391696793\n",
      "Bwd IAT Std\t0.08009979525074445\n",
      "Active Mean\t0.07590030696535331\n",
      "Bwd IAT Min\t0.07552757192054471\n",
      "Active Std\t0.0696217162658118\n",
      "Idle Mean\t0.069297552320734\n",
      "Fwd IAT Min\t0.06891040683994405\n",
      "Active Min\t0.06597273058790702\n",
      "Fwd IAT Mean\t0.06455746253116558\n",
      "Fwd IAT Std\t0.06417815436232036\n",
      "Fwd IAT Max\t0.055787701072625005\n",
      "Bwd IAT Max\t0.055218405109308685\n",
      "Flow IAT Max\t0.05076004169364114\n",
      "Bwd IAT Mean\t0.04353350919648317\n",
      "Active Max\t0.0399038486969354\n",
      "Idle Std\t0.003020806400454983\n",
      "Idle Min\t0.0029491987303549485\n",
      "Idle Max\t0.0\n"
     ]
    }
   ],
   "source": [
    "# Determine important features\n",
    "\n",
    "# CODE HERE\n",
    "ft_imps = [ft for ft in zip(data.columns[5:28], model.feature_importances_)]\n",
    "ft_imps.sort(key=lambda ft: ft[1], reverse=True)\n",
    "print('Feature\\t\\tImportance')\n",
    "for ft in ft_imps: print('{}\\t{}'.format(ft[0].strip(), ft[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "1) What is the overall accuracy using the default parameters?  \n",
    "\n",
    "2) What is the confusion matrix for the tested approach?  What are the classes where the model performs well?  What are the classes where the model performs poorly?\n",
    "\n",
    "3) What are the top 5 most important features?\n",
    "\n",
    "4) What hyperparameters could you tune in the random forest to improve performance? What is the best accuracy you can attain?\n",
    "\n",
    "5) Bonus: How would you improve the pipeline above to automatically tune the hyperparameters?  How would you improve the pipeline to use multiple train/test splits?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
