{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4, Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n",
    "\n",
    "The data is separated into three folders: Attack_Data_Master, Training_Data_Master, and Validation_Data_Master\n",
    "These can be found here:\n",
    "data/exercise3/Training_Data_Master\n",
    "data/exercise3/Validation_Data_Master\n",
    "data/exercise3/Attack_Data_Master\n",
    "\n",
    "All of the data in Training_Data_Master and Validation_Data_Master is normal, \n",
    "and all the data in Attack_Data_Master is malicious\n",
    "\n",
    "For the purpose of this exercise, you will ignore the predefined training/validation splits, and simply use Training_Data_Master\n",
    "and Validation_Data_Master as a single pool of normal data\n",
    "\n",
    "As mentioned, each system call trace is stored as a single file.  Treat each system call trace as a separate datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load all the normal system call traces (i.e., everything in Training_Data_Master and Validation_Data_Master)\n",
    "\n",
    "# CODE HERE\n",
    "normal_data = []\n",
    "paths = [\n",
    "    'data/exercise3/Training_Data_Master',\n",
    "    'data/exercise3/Validation_Data_Master',\n",
    "    'data/exercise3/Attack_Data_Master'\n",
    "]\n",
    "for f_name in os.listdir(paths[0]):\n",
    "    with open(paths[0]+'/'+f_name, 'r') as f:\n",
    "        normal_data.append(f.read())\n",
    "for f_name in os.listdir(paths[1]):\n",
    "    with open(paths[1]+'/'+f_name, 'r') as f:\n",
    "        normal_data.append(f.read())\n",
    "\n",
    "# Load all the malicious system call traces (i.e., everything in Attack_Data_Master)\n",
    "\n",
    "# CODE HERE\n",
    "malicious_data = []\n",
    "for dir_name in os.listdir(paths[2]):\n",
    "    for f_name in os.listdir(paths[2]+'/'+dir_name):\n",
    "        with open(paths[2]+'/'+dir_name+'/'+f_name, 'r') as f:\n",
    "            malicious_data.append(f.read())\n",
    "\n",
    "# Hint: A useful way to load this is as one or two Python lists, where each entry in the list corresponds to the text string\n",
    "#       of system calls ids; feel free to use a single list for all the data, or separate lists for malicious versus normal\n",
    "#       data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Tokenize and create a dataset where each datapoint corresponds to (normalized) counts of \n",
    "system call n-grams. Try various sizes of ngrams.\n",
    "\n",
    "Reminder: A sequence of system call IDs that looks like this:\n",
    "'6 6 63 6 42'\n",
    "\n",
    "contains the following 3-grams:\n",
    "'6 6 63'\n",
    "'6 63 6'\n",
    "'63 6 42'\n",
    "\n",
    "Note: There are a number of ways you could code this up, but if you loaded the data\n",
    "as lists of strings, you could consider using some of the feature extraction methods in \n",
    "sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the classdemo notebook for an example of doing this\n",
    "# CODE HERE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt_vec = CountVectorizer(analyzer='word', ngram_range=(3,6))\n",
    "cnt_vec.fit(normal_data + malicious_data)\n",
    "# features = cnt_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(3, 6), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print(raw_cnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 50% of the data for the training set and the rest for the test set\n",
    "# CODE HERE\n",
    "X_train, X_test, y_train, y_test = train_test_split(com_data, com_labels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use Logistic Regression for this exercise\n",
    "# Feel free to experiment with the various hyperparameters available to you in sklearn\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the test data and predict labels for each data point in the test data\n",
    "# CODE HERE\n",
    "\n",
    "# Calculate and print the following metrics: precision, recall, f1-measure, and accuracy\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Varying class priors\n",
    "\n",
    "Create several new test datasets where you have randomly subsampled the number of \n",
    "attack datapoints.\n",
    "\n",
    "In particular, create the following datasets:\n",
    "- 10 datasets where 25% of the attack datapoints are removed from the original test set\n",
    "- 10 datasets where 50% of the attack datapoints are removed from the original test set\n",
    "- 10 datasets where 75% of the attack datapoints are removed from the original test set\n",
    "- 10 datasets where 90% of the attack datapoints are removed from the original test set\n",
    "- 10 datasets where 95% of the attack datapoints are removed from the original test set\n",
    "\n",
    "Report five sets of precision, recall, f1-measure, and accuracy corresponding to the following:\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 25% of attack datapoints removed\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 50% of attack datapoints removed\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 75% of attack datapoints removed\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 90% of attack datapoints removed\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 95% of attack datapoints removed\n",
    "\n",
    "Note: You will use the same model trained in part 1 for all of these datasets.  \n",
    "All you are varying is the class priors during the inference stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subsets of the test set by randomly discarding X% of points with label +1\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1) In Part 1, what size of ngrams gives the best performance? What are the tradeoffs as you change the size?\n",
    "\n",
    "2) In Part 1, how does performance change if we use simple counts as features (i.e., 1-grams) as opposed to counts of 2-grams? What does this tell you about the role of sequences in prediction for this dataset?\n",
    "\n",
    "3) How does performance change as a function of class prior in Part 2?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
